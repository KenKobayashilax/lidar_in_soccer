{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after running this, no need to restart the kurnel when you modify other files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import open3d\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import clusterization.clusterize as clusterizer\n",
    "from settings import DATA_PATH, BASE_PATH\n",
    "from utils.visualizer import save_camera_params\n",
    "from utils.handling_cluster import visualize_by_cluster_bbox, crop_cluster, visualize_bbox_result\n",
    "from detection.detect import compute_nearest_cluster_multicase, compute_bbox, save_bbox_result\n",
    "from plane_elimination.plane_elimination import eliminate_planes\n",
    "from plane_elimination.plane_equotions_list import planes_list, bool_list #list to define plane equotions\n",
    "from validation.data_preprocess import butter_lowpass_filter, align_dataframe, plot_validation_result, plot_validation_filtered_result, plot_trajectory\n",
    "\n",
    "data_type_name_pcd = \"LIVOX_Hallway_pcds\"\n",
    "experiment_name = \"Walking_to_end_1st\"\n",
    "dir_name = \"res100ms_start7s\"\n",
    "\n",
    "#directory path of pcd files\n",
    "directory_path = os.path.join(DATA_PATH, data_type_name_pcd, experiment_name, dir_name)\n",
    "#'{DATA_PATH}/LIVOX_Hallway_pcds/jogging_fast_4th/res100ms_start13.5s'\n",
    "\n",
    "#add save_path\n",
    "experiment_name_clustered = experiment_name + \"_clustered\"\n",
    "dir_name_clustered= dir_name + \"_clustered\"\n",
    "folder_clustered = os.path.join(DATA_PATH, data_type_name_pcd, experiment_name_clustered, dir_name_clustered)\n",
    "\n",
    "if not os.path.exists(folder_clustered):\n",
    "    os.makedirs(folder_clustered)\n",
    "\n",
    "# make the list of files\n",
    "file_list = []\n",
    "for filename in os.listdir(directory_path):\n",
    "    if os.path.isfile(os.path.join(directory_path, filename)):\n",
    "        file_list.append(os.path.join(directory_path, filename))\n",
    "        \n",
    "#select your view point and close your window.\n",
    "pcd = open3d.io.read_point_cloud(file_list[0])\n",
    "cam_params = save_camera_params(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add save_path\n",
    "experiment_name_tracked = experiment_name + \"_bbox_tracked\"  #\"jogging_fast_4th_bbox_tracked\"\n",
    "dir_name_tracked= dir_name + \"_bbox_tracked\"  #res100ms_start13.5s_bbox_tracked\n",
    "folder_tracked = os.path.join(DATA_PATH, data_type_name_pcd, experiment_name_tracked, dir_name_tracked)\n",
    "#.\\data\\LIVOX_Hallway_pcds\\jogging_fast_4th_bbox_tracked\\res100ms_start13.5s_bbox_tracked\n",
    "\n",
    "if not os.path.exists(folder_tracked):\n",
    "    os.makedirs(folder_tracked)\n",
    "\n",
    "#initialization\n",
    "eps = 0.8\n",
    "center_prev_list = []  #initialize the center list for the next frame\n",
    "center_prev = np.zeros(3) #initialize center of human cluster in previous frame\n",
    "cluster_ids = []\n",
    "\n",
    "#clusterize each files and visualize.\n",
    "for i, pcd_file in enumerate(file_list):\n",
    "    pcd = open3d.io.read_point_cloud(pcd_file)\n",
    "    \n",
    "    pcd_clustered = folder_clustered + \"/\" + os.path.basename(pcd_file) #pcd_clustered_save_path   \n",
    "    \n",
    "    #eliminate points by planes\n",
    "    pcd = eliminate_planes(pcd, planes_list=planes_list, bool_list=bool_list, visualize=False)\n",
    "    \n",
    "    #clusterization\n",
    "    pcd, labels = clusterizer.clusterize(pcd, eps=eps,\n",
    "                             time_duration=None, #time duration that each windows open for. If you choose None, close window manually.\n",
    "                             window_name=os.path.basename(pcd_file), #window name changes accorrding to file name.\n",
    "                             cam_params=cam_params,#camera parameter(view point) you selected\n",
    "                             save_path=pcd_clustered,\n",
    "                             visualize=False\n",
    "                             ) \n",
    "    \n",
    "    \n",
    "    filtered_labels = compute_bbox(pcd,labels)\n",
    "    \n",
    "    \n",
    "    #color of points in cluster_id is changed into red.\n",
    "    #pcd = change_cluster_color(pcd, labels, cluster_id=filtered_labels)\n",
    "    #visualizer.visualize(pcd, time_duration=None, cam_params=cam_params)\n",
    "    \n",
    "    #select human cluster in first frame\n",
    "    if i==0:\n",
    "        visualize_by_cluster_bbox(pcd, labels, filtered_labels)\n",
    "        filtered_labels = input(\"Please enter cluster ids, format example: 0,1,2.. \").split(',')\n",
    "        filtered_labels = [int(x) for x in filtered_labels]\n",
    "        \n",
    "    human_clusters = np.empty((0,3))\n",
    "    #select cluster id in comand line. check each window name.\n",
    "    for inx, fl_label in enumerate(filtered_labels):\n",
    "        if i==0:                                     # for the first frame\n",
    "            cluster_id = fl_label\n",
    "        else:\n",
    "            inx, cluster_id = compute_nearest_cluster_multicase(pcd, labels, fl_label, center_prev_list)\n",
    "            \n",
    "        #crop (and save) selected cluser\n",
    "        cropped_pcd = crop_cluster(pcd, labels, cluster_id=cluster_id, visualize=False)\n",
    "        \n",
    "        center_tmp = cropped_pcd.get_center()\n",
    "\n",
    "        \n",
    "        if i==0:   \n",
    "            center_prev_list.append([inx, center_tmp])\n",
    "\n",
    "            # save the cropped cluster(pcd, save_path)\n",
    "            save_bbox_result(inx, folder_tracked, pcd_file, cropped_pcd)\n",
    "\n",
    "            human_clusters = np.append(human_clusters, cropped_pcd.points, axis=0)\n",
    "            \n",
    "        else:  #update center if current cluster is close to previous one\n",
    "            center_prev = center_prev_list[inx][1]\n",
    "            current_dist = np.linalg.norm (center_prev - center_tmp)\n",
    "            if 0.1< current_dist < 5:\n",
    "                #update the previous center list\n",
    "                center_prev_list[inx][1] = center_tmp\n",
    "                # save the cropped cluster(pcd, save_path)\n",
    "                save_bbox_result(inx, folder_tracked, pcd_file, cropped_pcd)\n",
    "                \n",
    "                human_clusters = np.append(human_clusters, cropped_pcd.points, axis=0)\n",
    "\n",
    "    # visulize the bbox result of each frame\n",
    "    visualize_bbox_result(pcd, human_clusters, time_duration=0.2, cam_params=cam_params, visualize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### get center of mass of the cluster and calculate velocity ###\n",
    "\n",
    "# get each subfolders in folder_tracked (different players if exist)\n",
    "subfolders = [f.path for f in os.scandir(folder_tracked) if f.is_dir()]\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    print(f\"Processing folder: {subfolder}\")\n",
    "    subfolder_name = os.path.basename(subfolder)\n",
    "    \n",
    "    center_list = []\n",
    "    time_list = []\n",
    "    pcd_files = [f.path for f in os.scandir(subfolder) if f.is_file() and f.name.endswith(\".pcd\")]\n",
    "    \n",
    "    # Extracting file names without the \".pcd\" extension\n",
    "    pcd_names_without_extension = [os.path.splitext(os.path.basename(pcd_file))[0] for pcd_file in pcd_files]\n",
    "\n",
    "    for pcd_file in pcd_files:\n",
    "        print(f\"Reading PCD file: {pcd_file}\")\n",
    "        \n",
    "        # file name without extension (frame time)\n",
    "        frame_time = os.path.splitext(os.path.basename(pcd_file))[0]\n",
    "        \n",
    "        # read point cloud cluster\n",
    "        point_cloud = open3d.io.read_point_cloud(pcd_file)\n",
    "        \n",
    "        # get center of cluster\n",
    "        center = point_cloud.get_center()\n",
    "        \n",
    "        center_list.append(center) \n",
    "        time_list.append(frame_time)  # unit: ms\n",
    "\n",
    "    \n",
    "    # calculate velocity\n",
    "    # take only the x,y-axis\n",
    "    centers_xy = [row[:2] for row in center_list]\n",
    "    time_list = [float(num) for num in time_list]\n",
    "    \n",
    "    \n",
    "    velocities = []\n",
    "    csv_data = []\n",
    "    \n",
    "    for i in range(1, len(centers_xy)):\n",
    "        # calculate displacement\n",
    "        displacement_x = centers_xy[i][0] - centers_xy[i - 1][0]\n",
    "        displacement_y = centers_xy[i][1] - centers_xy[i - 1][1]\n",
    "\n",
    "        # calculate time interval\n",
    "        time_interval = time_list[i] - time_list[i - 1]\n",
    "\n",
    "        velocity_x = 1000 * displacement_x / time_interval  # *1000 cuz of the time unit is ms\n",
    "        velocity_y = 1000 * displacement_y / time_interval\n",
    "\n",
    "        velocity = math.sqrt(velocity_x**2 + velocity_y**2)\n",
    "        \n",
    "        # Adjust velocity if velocity_y is negative\n",
    "        if velocity_x < 0:\n",
    "            velocity = -velocity\n",
    "        \n",
    "        velocities.append(velocity)\n",
    "        \n",
    "        csv_data.append((time_list[i]/1000, velocity)) #convert time unit to m/s\n",
    "\n",
    "\n",
    "    # save velocity data to a csv file\n",
    "    csv_file = \"velocity.csv\"\n",
    "    csv_path = os.path.join(folder_tracked, subfolder_name, csv_file)\n",
    "    \n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        writer.writerow(['Time', 'Velocity'])\n",
    "\n",
    "        for time, velocity in csv_data:\n",
    "            writer.writerow([time, velocity])\n",
    "\n",
    "    # save trajectory figure\n",
    "    trajectory_figure = \"trajectory_plot.png\"\n",
    "    figure_path = os.path.join(folder_tracked, subfolder_name, trajectory_figure)\n",
    "    \n",
    "    plot_trajectory(centers_xy, figure_path)\n",
    "    \n",
    "print(\"end\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Evaluation_DataProcessing ###################\n",
    "from validation.data_preprocess import cs_interpolate\n",
    "\n",
    "########## obtain and preprocess all csv data ###########\n",
    "# directory path of measurement csv file\n",
    "ms_folder = \"0_class\"\n",
    "ms_file = \"velocity.csv\"\n",
    "ms_directory_path = os.path.join(BASE_PATH, folder_tracked, ms_folder, ms_file)\n",
    "ms = pd.read_csv(ms_directory_path)\n",
    "\n",
    "# directory path of ground truth csv file\n",
    "gt_folder = \"Data\"\n",
    "gt_file_name = \"Run_1.csv\"\n",
    "gt_directory_path = os.path.join(BASE_PATH, gt_folder, gt_file_name)\n",
    "gt = pd.read_csv(gt_directory_path)\n",
    "\n",
    "# remove rows containing NaN values\n",
    "gt = gt.dropna()\n",
    "\n",
    "# Convert the 'Time' column to timedelta\n",
    "ms['Time'] = pd.to_timedelta(ms['Time'], unit='s')\n",
    "gt['Time'] = pd.to_timedelta(gt['Time'], unit='s')\n",
    "\n",
    "# Set 'Time' as the index for both DataFrames\n",
    "ms.set_index('Time', inplace=True)\n",
    "gt.set_index('Time', inplace=True)\n",
    "\n",
    "# Resample the measurement data to match the higher sampling rate of gt\n",
    "ms = ms.resample('0.01S').mean().interpolate()\n",
    "\n",
    "\n",
    "\n",
    "############### butter filter #####################\n",
    "ms_cutoff_frequency = 1.0  # cut-off frequency\n",
    "ms_sample_rate = 100.0  # sampling rate\n",
    "\n",
    "gt_cutoff_frequency = 1.0  # cut-off frequency\n",
    "gt_sample_rate = 100.0  # sampling rate\n",
    "\n",
    "ms_filtered_velocity = butter_lowpass_filter(ms['Velocity'], ms_cutoff_frequency, ms_sample_rate, order=4)\n",
    "ms['Filtered_Velocity'] = ms_filtered_velocity\n",
    "\n",
    "# Resample the measurement data to match the higher sampling rate of gt\n",
    "ms = ms.resample('0.01S').mean().interpolate()\n",
    "\n",
    "gt_filtered_velocity = butter_lowpass_filter(gt['Velocity'], gt_cutoff_frequency, gt_sample_rate, order=1)\n",
    "gt['Filtered_Velocity'] = gt_filtered_velocity\n",
    "\n",
    "# apply to the filtered gt data\n",
    "len_diff_filtered = len(gt) - len(ms)\n",
    "min_rmse_filtered, best_chunk_filtered, best_offset_filtered = align_dataframe(gt, ms, len_diff_filtered, filter=True)\n",
    "\n",
    "\n",
    "############# align the groundtruth and measurement data ############\n",
    "# apply to the original gt data\n",
    "len_diff = len(gt) - len(ms)\n",
    "min_rmse, best_chunk, best_offset = align_dataframe(gt, ms, len_diff, filter=False)\n",
    "\n",
    "print(f\"Complete the data alignment !!!!\")\n",
    "print(f\"Minimum Root Mean Square Error(RMSE): {min_rmse}\")\n",
    "print(f\"Best Offset: {best_offset}\")\n",
    "\n",
    "# Plot the results\n",
    "plt = plot_validation_result(len_diff, best_chunk, gt, ms)\n",
    "plt_file = \"validation_plot.png\"\n",
    "plt_path = os.path.join(BASE_PATH, folder_tracked, ms_folder, plt_file)\n",
    "plt.savefig(plt_path)\n",
    "plt.show()\n",
    "\n",
    "# FOR FILTERED DATA\n",
    "print(f\"Complete the filtered data alignment !!!!\")\n",
    "print(f\"Minimum Root Mean Square Error (RMSE) for filtered data: {min_rmse_filtered}\")\n",
    "print(f\"Best Offset for filtered data: {best_offset_filtered}\")\n",
    "\n",
    "f_plt = plot_validation_filtered_result(len_diff_filtered, best_chunk_filtered, gt, ms)\n",
    "f_plt_file = \"filtered_validation_plot.png\"\n",
    "f_plt_path = os.path.join(BASE_PATH, folder_tracked, ms_folder, f_plt_file)\n",
    "f_plt.savefig(f_plt_path)\n",
    "\n",
    "\n",
    "# save the RMSE to file\n",
    "rmse_csv_file = \"rmse.csv\"\n",
    "rmse_csv_path = os.path.join(BASE_PATH, folder_tracked, ms_folder, rmse_csv_file)\n",
    "    \n",
    "with open(rmse_csv_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    writer.writerow(['NAME', 'RMSE', 'Filtered RMSE'])\n",
    "    writer.writerow([experiment_name, min_rmse, min_rmse_filtered])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Finish!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
